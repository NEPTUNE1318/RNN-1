{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"2\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(22)\n",
    "np.random.seed(22)\n",
    "assert tf.__version__.startswith('2.')\n",
    "\n",
    "batch_size = 128\n",
    "total_words = 10000\n",
    "max_review_len = 80\n",
    "embedding_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_shape: (25000, 80) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64)\n",
      "x_test_shape: (25000, 80)\n",
      "(128, 80)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=total_words)\n",
    "\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
    "test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_data = test_data.batch(batch_size, drop_remainder=True)\n",
    "print('x_train_shape:', x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))\n",
    "print('x_test_shape:', x_test.shape)\n",
    "\n",
    "sample = next(iter(test_data))\n",
    "print(sample[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_Build(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, units):\n",
    "        super(GRU_Build, self).__init__()\n",
    "\n",
    "        self.state0 = [tf.zeros([batch_size, units])]\n",
    "        self.state1 = [tf.zeros([batch_size, units])]\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(total_words, embedding_len, input_length=max_review_len)\n",
    "        self.RNNCell0 = tf.keras.layers.GRUCell(units, dropout=0.5)\n",
    "        self.RNNCell1 = tf.keras.layers.GRUCell(units, dropout=0.5)\n",
    "        self.outlayer = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs\n",
    "        x = self.embedding(x)\n",
    "        state0 = self.state0\n",
    "        state1 = self.state1\n",
    "        for word in tf.unstack(x, axis=1):    \n",
    "            out0, state0 = self.RNNCell0(word, state0, training)   \n",
    "            out1, state1 = self.RNNCell1(out0, state1, training)\n",
    "        x = self.outlayer(out1)\n",
    "        prob = tf.sigmoid(x)\n",
    "\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "195/195 [==============================] - 132s 483ms/step - loss: 0.5183 - accuracy: 0.7229\n",
      "Epoch 2/4\n",
      "195/195 [==============================] - 141s 722ms/step - loss: 0.3201 - accuracy: 0.8654 - val_loss: 0.3670 - val_accuracy: 0.8414\n",
      "Epoch 3/4\n",
      "195/195 [==============================] - 78s 401ms/step - loss: 0.2634 - accuracy: 0.8953\n",
      "Epoch 4/4\n",
      "195/195 [==============================] - 102s 523ms/step - loss: 0.2249 - accuracy: 0.9121 - val_loss: 0.3900 - val_accuracy: 0.8367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1af97d75cf0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "units = 64\n",
    "epochs = 4\n",
    "t0 = time.time()\n",
    "\n",
    "model = GRU_Build(units)\n",
    "\n",
    "log_dir = 'img/log7-3/'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,\n",
    "                                                      histogram_freq=1, profile_batch=0)\n",
    "    \n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss=tf.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'],\n",
    "              experimental_run_tf_function=False)\n",
    "    \n",
    "model.fit(train_data, epochs=epochs, validation_data=test_data, callbacks=[tensorboard_callback], validation_freq=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![accuracy](./img/accuracy-3.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('neptune1318')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8ab835351b5610f8cfecb5cb29ee2a48bbb112294c750a24c3d6705cccc4f89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
